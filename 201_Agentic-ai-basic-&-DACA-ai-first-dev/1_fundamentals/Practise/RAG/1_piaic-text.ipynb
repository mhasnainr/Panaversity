{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QgAapf_z875sEev_O9COE7TPHIKEXx6r","timestamp":1752758894511}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["RAG From: PIAIC"],"metadata":{"id":"S_ukmr-RugKM"}},{"cell_type":"code","source":["!pip install -Uq openai-agents langchain-community chromadb \"openai-agents[litellm]\" langchain-openai\n","!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ILJmVi4zniH","executionInfo":{"status":"ok","timestamp":1752759661085,"user_tz":-300,"elapsed":12453,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"c8870816-d542-49b0-9ec8-a7c4af7f4701"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.8.0)\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"],"metadata":{"id":"GhFV4Yqy1Htz","executionInfo":{"status":"ok","timestamp":1752759669729,"user_tz":-300,"elapsed":1094,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import nest_asyncio\n","nest_asyncio.apply()"],"metadata":{"id":"V7dQ3pdI1P0a","executionInfo":{"status":"ok","timestamp":1752759671681,"user_tz":-300,"elapsed":36,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install -Uq openai-agents langchain-community chromadb \"openai-agents[litellm]\" langchain-openai langchain-google-genai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdSFRx7jche7","executionInfo":{"status":"ok","timestamp":1752759682774,"user_tz":-300,"elapsed":9607,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"a7be879b-b1b4-4d8a-8a15-4fe4b94226e0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -Uq openai-agents chromadb google-genai"],"metadata":{"id":"rKoogccfpDjc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752759756816,"user_tz":-300,"elapsed":8693,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"a8dc9949-6165-4ec0-d839-fc5ab13ef551"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.7/217.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Set your API keys (replace the placeholders with your actual keys)\n","# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"            # OpenAI API key for Agents SDK\n","GEMINI_API_KEY = userdata.get(\"GOOGLE_API_KEY\")       # Google API key\n","\n","# Import the necessary classes\n","from agents import Agent, Runner, function_tool   # OpenAI Agents SDK components\n","import chromadb                                   # ChromaDB client\n","from chromadb.utils import embedding_functions    # (optional, if using embedding functions directly)\n","from google import genai                          # Google GenAI SDK for GOOGLE\n","from google.genai.types import EmbedContentConfig"],"metadata":{"id":"H9ac_n7szsFI","executionInfo":{"status":"ok","timestamp":1752759803986,"user_tz":-300,"elapsed":4862,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Initialize ChromaDB in-memory client\n","chroma_client = chromadb.Client()  # default uses an in-memory SQLite store\n","\n","# Initialize Google GenAI client with the Gemini API key\n","client = genai.Client(api_key=GEMINI_API_KEY)\n"],"metadata":{"id":"b4iMI2WHpko4","executionInfo":{"status":"ok","timestamp":1752759814560,"user_tz":-300,"elapsed":531,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Define a few short text documents (e.g., Wikipedia-style snippets)\n","documents = [\n","    \"Cats are small, domesticated carnivorous mammals often valued by humans for companionship and for their ability to hunt vermin.\",\n","    \"Dogs are domesticated mammals, not natural wild animals. They were originally bred from wolves.\",\n","    \"The Apollo program was a series of space missions by NASA in the 1960s and 1970s aimed at landing humans on the Moon.\"\n","]\n","doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n","\n","# (Optional) Print the documents to verify\n","for i, doc in enumerate(documents, 1):\n","    print(f\"Document {i}: {doc[:60]}...\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GOwmIFHpnCp","executionInfo":{"status":"ok","timestamp":1752759824769,"user_tz":-300,"elapsed":28,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"5f6d8077-d8d6-4c82-fec6-c25588e4d1f2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Document 1: Cats are small, domesticated carnivorous mammals often value...\n","Document 2: Dogs are domesticated mammals, not natural wild animals. The...\n","Document 3: The Apollo program was a series of space missions by NASA in...\n"]}]},{"cell_type":"code","source":["# Embed each document using the Gemini embedding model\n","embed_model = \"gemini-embedding-exp-03-07\"\n","\n","# Generate embeddings for all documents in one call\n","response = client.models.embed_content(\n","    model=embed_model,\n","    contents=documents,\n","    config=EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")  # optimize embeddings for retrieval\n",")\n","\n","# Extract the embedding vectors from the response\n","doc_embeddings = [emb.values for emb in response.embeddings]\n","\n","# Check the number of embeddings and dimensionality of one embedding\n","print(f\"Generated {len(doc_embeddings)} embeddings.\")\n","print(f\"Dimension of first embedding: {len(doc_embeddings[0])}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycCnO1Tup0k6","executionInfo":{"status":"ok","timestamp":1752759830721,"user_tz":-300,"elapsed":1382,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"36d9db53-e87b-4e44-e79a-c443720f9561"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated 3 embeddings.\n","Dimension of first embedding: 3072\n"]}]},{"cell_type":"code","source":["print(f\"Sample of first embedding vector: {doc_embeddings[0][:5]}...\")  # print first 5 values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nYQG8AsJp1S6","executionInfo":{"status":"ok","timestamp":1752759840320,"user_tz":-300,"elapsed":24,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"242fb5bb-3351-4cad-f3ed-8d0dc1a31bc6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample of first embedding vector: [-0.02342979, 0.018499875, 0.012728111, -0.045184404, 0.0019269326]...\n"]}]},{"cell_type":"code","source":["# Create a ChromaDB collection for our documents\n","collection = chroma_client.create_collection(name=\"knowledge_base\")\n","\n","# Add documents, their embeddings, and IDs to the collection\n","collection.add(\n","    documents=documents,\n","    embeddings=doc_embeddings,\n","    ids=doc_ids\n",")\n","\n","# (Optional) verify collection size\n","print(\"Documents in collection:\", collection.count())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8GJ-Abrp4Ym","executionInfo":{"status":"ok","timestamp":1752759844174,"user_tz":-300,"elapsed":326,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"7373cf95-28ee-4949-ebee-d27e8c97083e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Documents in collection: 3\n"]}]},{"cell_type":"code","source":["# User's question\n","user_question = \"What was the goal of the Apollo program?\"\n","\n","# Embed the user query using the same model (use task_type RETRIEVAL_QUERY for queries)\n","query_response = client.models.embed_content(\n","    model=embed_model,\n","    contents=[user_question],\n","    config=EmbedContentConfig(task_type=\"RETRIEVAL_QUERY\")\n",")\n","query_vector = query_response.embeddings[0].values\n","# query_vector\n","\n","# Use ChromaDB to find the most similar document(s) to the query\n","results = collection.query(\n","    query_embeddings=[query_vector],\n","    n_results=2,  # fetch top 2 most similar docs\n","    # Remove 'ids' from the include list as it's not a valid option\n","    include=[\"documents\", \"distances\"]\n",")\n","results\n","\n","# Print out the retrieved documents and their similarity scores\n","# print(\"Query:\", user_question)\n","# for doc, score, doc_id in zip(results[\"documents\"][0], results[\"distances\"][0], results[\"ids\"][0]):\n","#     print(f\"- Retrieved {doc_id} with similarity score {score:.4f}: {doc[:60]}...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArIp4hp4p7Ae","executionInfo":{"status":"ok","timestamp":1752759851801,"user_tz":-300,"elapsed":430,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"c56aef66-e499-4208-d9c8-690931c30f53"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ids': [['doc3', 'doc2']],\n"," 'embeddings': None,\n"," 'documents': [['The Apollo program was a series of space missions by NASA in the 1960s and 1970s aimed at landing humans on the Moon.',\n","   'Dogs are domesticated mammals, not natural wild animals. They were originally bred from wolves.']],\n"," 'uris': None,\n"," 'included': ['documents', 'distances'],\n"," 'data': None,\n"," 'metadatas': None,\n"," 'distances': [[0.4427131414413452, 0.9165204763412476]]}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["print(f\"Sample of first embedding vector: {doc_embeddings[0][:5]}...\")  # print first 5 values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SspTvN-p-lp","executionInfo":{"status":"ok","timestamp":1752759858018,"user_tz":-300,"elapsed":36,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"f9bb0b7c-82fd-47d3-9bdb-ae441a1f560b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample of first embedding vector: [-0.02342979, 0.018499875, 0.012728111, -0.045184404, 0.0019269326]...\n"]}]},{"cell_type":"code","source":["# Prepare the context from the retrieved docs\n","retrieved_docs = results[\"documents\"][0]\n","context = \"\\n\\n\".join(retrieved_docs)\n","\n","# Formulate the prompt for the LLM\n","prompt = f\"\"\"Use the following context to answer the question.\n","\n","Context:\n","{context}\n","\n","Question:\n","{user_question}\n","\n","Answer the question using only the information from the context above.\"\"\"\n","print(prompt)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHvyepunspg0","executionInfo":{"status":"ok","timestamp":1752759861897,"user_tz":-300,"elapsed":122,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"a1533b14-0241-4bef-d2b6-424148fc33cb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Use the following context to answer the question.\n","\n","Context:\n","The Apollo program was a series of space missions by NASA in the 1960s and 1970s aimed at landing humans on the Moon.\n","\n","Dogs are domesticated mammals, not natural wild animals. They were originally bred from wolves.\n","\n","Question:\n","What was the goal of the Apollo program?\n","\n","Answer the question using only the information from the context above.\n"]}]},{"cell_type":"code","source":["# Use the Gemini 2.5 flash model to get an answer based on the context\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash\",\n","    contents=prompt\n",")\n","answer = response.text\n","\n","print(\"Answer:\", answer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idML1m1psuMH","executionInfo":{"status":"ok","timestamp":1752759962256,"user_tz":-300,"elapsed":1457,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"a1438436-ad9a-428d-b0d0-679b157ed165"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Answer: The goal of the Apollo program was landing humans on the Moon.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"FoNio_NAt9jC"}},{"cell_type":"code","source":["import nest_asyncio\n","nest_asyncio.apply()"],"metadata":{"id":"09O_c-3xt9z_","executionInfo":{"status":"ok","timestamp":1752759967526,"user_tz":-300,"elapsed":37,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n","from agents.run import RunConfig\n","\n","gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n","\n","\n","# Check if the API key is present; if not, raise an error\n","if not gemini_api_key:\n","    raise ValueError(\"GOOGLE_API_KEY is not set. Please ensure it is defined in your .env file.\")\n","\n","#Reference: https://ai.google.dev/gemini-api/docs/openai\n","external_client = AsyncOpenAI(\n","    api_key=gemini_api_key,\n","    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",")\n","\n","model = OpenAIChatCompletionsModel(\n","    model=\"gemini-2.5-flash\",\n","    openai_client=external_client\n",")\n","\n","config = RunConfig(\n","    model=model,\n","    model_provider=external_client,\n","    tracing_disabled=True\n",")"],"metadata":{"id":"w14gGff8t-ln","executionInfo":{"status":"ok","timestamp":1752760032004,"user_tz":-300,"elapsed":1109,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from agents import set_default_openai_client, set_tracing_disabled\n","\n","set_tracing_disabled(True)\n","gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n","\n","\n","external_client = AsyncOpenAI(\n","    api_key=gemini_api_key,\n","    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",")\n","set_default_openai_client(external_client)"],"metadata":{"id":"GT7Qr2d1uEiV","executionInfo":{"status":"ok","timestamp":1752760076820,"user_tz":-300,"elapsed":1252,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from agents.tool import function_tool"],"metadata":{"id":"zLH4D9KguFIB","executionInfo":{"status":"ok","timestamp":1752760082602,"user_tz":-300,"elapsed":118,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["@function_tool\n","def answer_from_knowledge_base(query: str) -> str:\n","    \"\"\"\n","    Tool: Given a user query, this tool searches the knowledge base and returns an answer using retrieved documents.\n","    \"\"\"\n","    # Embed the query\n","    q_resp = client.models.embed_content(\n","        model=embed_model,\n","        contents=[query],\n","        config=EmbedContentConfig(task_type=\"RETRIEVAL_QUERY\")\n","    )\n","    q_vector = q_resp.embeddings[0].values\n","    # Search the vector store\n","    res = collection.query(query_embeddings=[q_vector], n_results=1, include=[\"documents\"])\n","    top_doc = res[\"documents\"][0][0]  # top result's text\n","    # Construct prompt with retrieved context\n","    prompt = f\"Context:\\n{top_doc}\\n\\nQuestion:\\n{query}\\n\\nAnswer the question using only the context above.\"\n","    # Generate answer with Gemini 2.5 Flash\n","    resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n","    return resp.text"],"metadata":{"id":"0uw4wh7dsyKZ","executionInfo":{"status":"ok","timestamp":1752760106785,"user_tz":-300,"elapsed":366,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["!pip install -Uq openai-agents langchain-community chromadb langchain-openai langchain-google-genai litellm\n"],"metadata":{"id":"a91srJvwqfvX","executionInfo":{"status":"ok","timestamp":1752760119317,"user_tz":-300,"elapsed":8464,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Install necessary packages\n","!pip install -Uq openai-agents langchain-community chromadb langchain-openai langchain-google-genai litellm\n","\n","# Import necessary libraries\n","import asyncio\n","from agents import function_tool\n","import chromadb\n","from google import genai\n","from google.genai.types import EmbedContentConfig\n","import nest_asyncio\n","\n","# Apply nest_asyncio for compatibility with notebooks\n","nest_asyncio.apply()\n","\n","# Set up tracing\n","set_tracing_disabled(True)\n","\n","# Get Gemini API key\n","gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n","if not gemini_api_key:\n","    raise ValueError(\"GOOGLE_API_KEY is not set. Please ensure it is defined in your userdata.\")\n","\n","# Configure the OpenAI-compatible client for Gemini\n","external_client = AsyncOpenAI(\n","    api_key=gemini_api_key,\n","    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",")\n","\n","# Set this as the default OpenAI client for agents\n","set_default_openai_client(external_client)\n","\n","# Initialize Google GenAI client for RAG embedding/generation\n","client = genai.Client(api_key=gemini_api_key)\n","\n","# Initialize ChromaDB in-memory client\n","chroma_client = chromadb.Client()\n","\n","# Define and embed documents\n","documents = [\n","    \"Cats are small, domesticated carnivorous mammals often valued by humans for companionship and for their ability to hunt vermin.\",\n","    \"Dogs are domesticated mammals, not natural wild animals. They were originally bred from wolves.\",\n","    \"The Apollo program was a series of space missions by NASA in the 1960s and 1970s aimed at landing humans on the Moon.\"\n","]\n","doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n","embed_model = \"gemini-embedding-exp-03-07\" # Or whichever model you used\n","\n","# Generate embeddings for all documents in one call\n","response = client.models.embed_content(\n","    model=embed_model,\n","    contents=documents,\n","    config=EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",")\n","doc_embeddings = [emb.values for emb in response.embeddings]\n","\n","# Create or get the collection\n","collection = chroma_client.get_or_create_collection(name=\"knowledge_base1\")\n","\n","# Add documents, handling potential duplicates\n","try:\n","    collection.add(\n","        documents=documents,\n","        embeddings=doc_embeddings,\n","        ids=doc_ids\n","    )\n","except Exception as e:\n","    print(f\"Could not add documents to collection, potentially they already exist: {e}\")\n","\n","\n","# Define the RAG tool using the accessible clients and variables\n","@function_tool\n","def answer_from_knowledge_base(query: str) -> str:\n","    \"\"\"\n","    Tool: Given a user query, this tool searches the knowledge base and returns an answer using retrieved documents.\n","    \"\"\"\n","    print(f\"[Debug] RAG function call with query {query}\")\n","    # Embed the query using the accessible 'client' and 'embed_model'\n","    q_resp = client.models.embed_content(\n","        model=embed_model,\n","        contents=[query],\n","        config=EmbedContentConfig(task_type=\"RETRIEVAL_QUERY\")\n","    )\n","    q_vector = q_resp.embeddings[0].values\n","    # Search the vector store using the accessible 'collection'\n","    res = collection.query(query_embeddings=[q_vector], n_results=1, include=[\"documents\"])\n","    print(f\"[Debug] RAG vector db output {res}\")\n","    # Check if any documents were returned\n","    if res and res.get(\"documents\") and res[\"documents\"][0]:\n","        top_doc = res[\"documents\"][0][0]  # top result's text\n","        # Construct prompt with retrieved context\n","        prompt = f\"Context:\\n{top_doc}\\n\\nQuestion:\\n{query}\\n\\nAnswer the question using only the context above.\"\n","        # Generate answer with Gemini 2.5 Flash using the accessible 'client'\n","        resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n","        print(f\"[Debug] RAG function call with response ***{resp.text}***\")\n","        return resp.text\n","    else:\n","        return \"Could not find relevant information in the knowledge base.\"\n","\n","# Create an agent that can use the knowledge base tool\n","# Use OpenAIChatCompletionsModel with the external_client\n","qa_agent = Agent(\n","    name=\"QA Agent\",\n","    instructions=\"You are a helpful assistant. If the user asks a question, use your tools to find information in the knowledge base and answer with that information.\",\n","    tools=[answer_from_knowledge_base],\n","    # Use OpenAIChatCompletionsModel with the pre-configured external_client\n","    model=OpenAIChatCompletionsModel(\n","        model=\"gemini-2.5-flash\", # Specify the model name compatible with the OpenAI-like endpoint\n","        openai_client=external_client\n","    )\n",")\n","\n","async def main():\n","    agent_question = \"Which domestic animal was originally bred from wolves? what do you know about Apollo?\"\n","\n","    # Run the agent\n","    result = await Runner.run(qa_agent, agent_question)\n","\n","    # Extract and print the final answer\n","    print(\"Agent result:\", result)\n","    print(\"Agent's answer:\", result.final_output)\n","\n","if __name__ == \"__main__\":\n","    asyncio.run(main())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-kIHzOLs8Vg","executionInfo":{"status":"ok","timestamp":1752760362413,"user_tz":-300,"elapsed":27534,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"e83abf38-2ce6-4f1d-89f2-75f49a306357"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["[Debug] RAG function call with query Which domestic animal was originally bred from wolves?\n","[Debug] RAG vector db output {'ids': [['doc2']], 'embeddings': None, 'documents': [['Dogs are domesticated mammals, not natural wild animals. They were originally bred from wolves.']], 'uris': None, 'included': ['documents'], 'data': None, 'metadatas': None, 'distances': None}\n","[Debug] RAG function call with response ***Dogs***\n","[Debug] RAG function call with query What do you know about Apollo?\n","[Debug] RAG vector db output {'ids': [['doc3']], 'embeddings': None, 'documents': [['The Apollo program was a series of space missions by NASA in the 1960s and 1970s aimed at landing humans on the Moon.']], 'uris': None, 'included': ['documents'], 'data': None, 'metadatas': None, 'distances': None}\n","[Debug] RAG function call with response ***Apollo was a program that was a series of space missions by NASA in the 1960s and 1970s, aimed at landing humans on the Moon.***\n","Agent result: RunResult:\n","- Last agent: Agent(name=\"QA Agent\", ...)\n","- Final output (str):\n","    Dogs were originally bred from wolves. The Apollo program was a series of space missions conducted by NASA in the 1960s and 1970s, with the goal of landing humans on the Moon.\n","- 5 new item(s)\n","- 2 raw response(s)\n","- 0 input guardrail result(s)\n","- 0 output guardrail result(s)\n","(See `RunResult` for more details)\n","Agent's answer: Dogs were originally bred from wolves. The Apollo program was a series of space missions conducted by NASA in the 1960s and 1970s, with the goal of landing humans on the Moon.\n"]}]},{"cell_type":"markdown","source":["## With PDF"],"metadata":{"id":"vGbTDO9qq1hB"}},{"cell_type":"code","source":["!pip install pypdf\n","from langchain_community.document_loaders import PyPDFLoader\n","\n","def load_and_split_pdf(file_path: str):\n","  \"\"\"Loads a PDF and splits it into pages.\"\"\"\n","  loader = PyPDFLoader(file_path)\n","  pages = loader.load_and_split()\n","  return pages\n","\n","# Example usage: Upload a PDF and process it\n","from google.colab import files\n","uploaded = files.upload()\n","\n","pdf_file_path = list(uploaded.keys())[0]\n","pdf_pages = load_and_split_pdf(pdf_file_path)\n","\n","print(f\"Loaded {len(pdf_pages)} pages from {pdf_file_path}\")\n","\n","# Extract text content from the pages\n","pdf_documents_text = [page.page_content for page in pdf_pages]\n","pdf_doc_ids = [f\"pdf_page_{i+1}\" for i in range(len(pdf_pages))]\n","\n","# Embed the PDF document content\n","pdf_embeddings_response = client.models.embed_content(\n","    model=embed_model,\n","    contents=pdf_documents_text,\n","    config=EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",")\n","pdf_doc_embeddings = [emb.values for emb in pdf_embeddings_response.embeddings]\n","\n","# Add the PDF content and embeddings to the ChromaDB collection\n","# Get the existing collection or create a new one if it doesn't exist\n","collection = chroma_client.get_or_create_collection(name=\"knowledge_base1\")\n","\n","try:\n","    collection.add(\n","        documents=pdf_documents_text,\n","        embeddings=pdf_doc_embeddings,\n","        ids=pdf_doc_ids\n","    )\n","    print(f\"Added {len(pdf_pages)} PDF pages to the knowledge base.\")\n","except Exception as e:\n","    print(f\"Could not add PDF documents to collection, potentially they already exist: {e}\")\n","\n","print(\"Total documents in collection:\", collection.count())\n","\n","# The rest of your agent and RAG tool code should work with the updated collection.\n","# You can now ask questions that might be answered by the content of the uploaded PDF.\n"],"metadata":{"id":"a16HxnL8u-SI","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"ok","timestamp":1752760428038,"user_tz":-300,"elapsed":31109,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"615d56de-f758-476f-842b-a7710715ee02"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.8.0)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-441d35c1-fff9-4cf3-8ee1-e5da3db4738b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-441d35c1-fff9-4cf3-8ee1-e5da3db4738b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving oai-australia.pdf to oai-australia.pdf\n","Loaded 18 pages from oai-australia.pdf\n","Added 18 PDF pages to the knowledge base.\n","Total documents in collection: 21\n"]}]},{"cell_type":"code","source":["async def main_pdf_question():\n","    # Ask a question that relates to the uploaded PDF content\n","    pdf_question = \"What is the potential of AI infrastructure in Australia by 2030\" # Replace with a specific question about your PDF\n","\n","    # Run the agent with the new question\n","    result = await Runner.run(qa_agent, pdf_question)\n","\n","    # Extract and print the final answer\n","    print(\"Agent result for PDF question:\", result)\n","    print(\"Agent's answer for PDF question:\", result.final_output)\n","\n","if __name__ == \"__main__\":\n","    asyncio.run(main_pdf_question())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCHCSQgNr0bm","executionInfo":{"status":"ok","timestamp":1752760572481,"user_tz":-300,"elapsed":9270,"user":{"displayName":"Hasnain","userId":"07027081452957922943"}},"outputId":"3471facb-827a-420f-cd31-377f07be510c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[Debug] RAG function call with query potential of AI infrastructure in Australia by 2030\n","[Debug] RAG vector db output {'ids': [['pdf_page_14']], 'embeddings': None, 'documents': [['AI in Australia\\nOpenAI’s Economic Blueprint\\n12\\nAustralia has the potential to become \\nthe Indo-Pacific’s trusted hub for AI \\ninfrastructure\\nOpenAI’s Stargate, a multibillion-dollar data centre project \\nin the US, is already generating thousands of jobs and \\nexpanding critical AI infrastructure. It offers a blueprint for \\nhow strategic compute investments can drive economic \\ngrowth, workforce development, and technological \\nleadership. Australia now has an opportunity to benefit in the \\nsame way.\\nEconomic research16 indicates that technologies usually take \\ndecades to diffuse across the world. ChatGPT, however, hit \\n100 million users in two months, ushering in a new paradigm \\nfor the pace of technological progress and the need for \\nmeaningfully more compute infrastructure than Australians \\ncurrently have access to.\\nAustralia leads on the core building blocks of data centre \\ncompetitiveness: it has the highest land availability among \\npeer nations, strong policy stability, efficient permitting \\nprocesses, and abundant access to renewable energy. These \\nadvantages, more than just low average electricity costs, \\nreinforce its appeal for major infrastructure investment.\\n16\\u2003\\u2003 Comin, Diego and Bart Hobijn (2010) “An Exploration of Technology Diffusion.” American Economic Review, 100 (5): 2031–59\\n17\\u2003\\u2003 Mandala Partners (2024) Empowering Australia’s Digital Future\\nAI models are growing larger and more widely used, driving \\nexponential demand for compute. Without expanded \\ndata centre capacity, Australia risks bottlenecks that limit \\ninnovation, delay adoption, and push development offshore. \\n \\nData centre capacity will more than \\ndouble by the end of the decade, \\ncreate over 8,000 jobs, and affect \\nnearly every sector of the economy \\nRising demand for AI and digital services is expected to more \\nthan double Australia’s data centre capacity, from 1,350 \\nmegawatts (MW) today to 3,100 MW by 2030, attracting up \\nto A$26 billion in additional investment.17 Major projects from \\nAirTrunk, AWS, CDC, Microsoft, and NEXTDC are already \\nplanned. This expansion will drive job growth across the \\ntech sector, with data centre operations forecast to support \\n17,900 full-time equivalent (FTE) jobs by 2030, up from 9,600 \\ntoday.17 Most of these new roles will be in ongoing operations \\n– tech trades, engineers, and ICT professionals. These \\nfigures reflect direct impacts only, and don’t capture the \\nwider economic flow-on effects this growth will bring.\\nAI Infrastructure\\nData centre deployable capacity in Australia Australia’s AI infrastructure could create 8,300 extra jobs\\nMegawatt (MW), 2024-2030F\\nSource: Mandala Partners (2024) Empowering Australia’s Digital Future; Mandala analysis.\\nData centre jobs in Australia, FTE jobs, 2024-2030F\\n2.3x\\n1350 MW\\n2024 2030F 2024 Additional jobs created 2030F\\n3,100 MW\\n9,600\\n17,900\\n8,300']], 'uris': None, 'included': ['documents'], 'data': None, 'metadatas': None, 'distances': None}\n","[Debug] RAG function call with response ***By 2030, Australia has the potential to become the Indo-Pacific’s trusted hub for AI infrastructure. Its data centre capacity is expected to more than double, from 1,350 megawatts (MW) today to 3,100 MW, attracting up to A$26 billion in additional investment.\n","\n","This expansion is forecast to support 17,900 full-time equivalent (FTE) jobs in data centre operations by 2030, an increase of 8,300 jobs from 9,600 today. Most of these new roles will be in ongoing operations, including tech trades, engineers, and ICT professionals. This growth is expected to affect nearly every sector of the economy and drive job growth across the tech sector, with wider economic flow-on effects.***\n","Agent result for PDF question: RunResult:\n","- Last agent: Agent(name=\"QA Agent\", ...)\n","- Final output (str):\n","    By 2030, Australia could become the Indo-Pacific's leading hub for AI infrastructure. Its data center capacity is projected to more than double from 1,350 MW to 3,100 MW, attracting up to A$26 billion in additional investment. This expansion is expected to create 17,900 full-time equivalent jobs in data center operations, an increase of 8,300 jobs, primarily in ongoing operations like tech trades, engineering, and ICT. This growth will likely impact nearly all economic sectors and drive job creation across the tech sector, with broader economic benefits.\n","- 3 new item(s)\n","- 2 raw response(s)\n","- 0 input guardrail result(s)\n","- 0 output guardrail result(s)\n","(See `RunResult` for more details)\n","Agent's answer for PDF question: By 2030, Australia could become the Indo-Pacific's leading hub for AI infrastructure. Its data center capacity is projected to more than double from 1,350 MW to 3,100 MW, attracting up to A$26 billion in additional investment. This expansion is expected to create 17,900 full-time equivalent jobs in data center operations, an increase of 8,300 jobs, primarily in ongoing operations like tech trades, engineering, and ICT. This growth will likely impact nearly all economic sectors and drive job creation across the tech sector, with broader economic benefits.\n"]}]}]}